# 获取句子向量方法概述（An Overview of Sentence Embedding Methods）

在基于神经网络的NLP研究中，词嵌入/向量是一种非常强大、有效的方法。到现在，word2vec和Glove已经是获取词向量的标准方法了（虽然也还有其他几种方法）。

与此形成对比的是，获取句子向量的方法仍然还不太明确（more elusive）。虽然可以通过监督学习训练词向量来得到句子向量，但通常情况下我们希望通过非监督的方式获取句子向量。例如，我们可能需要进行释义识别（paraphrase identification）或者建立一个高效获取相似句子的系统，但是并没有可以用来进行监督训练的数据。

在本文中，我将介绍几种非监督方式获取句子向量的重要方法。这绝对算不上全面，还有更多其他的方法；如果我有遗漏掉哪个重要方法，请在评论中指出我好改进本文。
<br>

## 1.Topic Models
虽然经常处在神经网络类方法的阴影下，对句子向量来说，主题模型仍然是一种非常强大且可解释的框架。

## 2.Paragraph Vectors (doc2vec)

## 3.Skip-Thought Vectors

## 4.FastSent

## 5.加权词向量

## 6.其他